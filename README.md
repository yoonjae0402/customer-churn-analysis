# Customer Churn Prediction Analysis

> Enterprise-grade machine learning project for predicting and preventing customer churn

[![Python](https://img.shields.io/badge/Python-3.9+-blue)](https://www.python.org/)
[![ML](https://img.shields.io/badge/ML-scikit--learn-orange)](https://scikit-learn.org/)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-success)](https://github.com)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

## üìä Project Overview

This project builds a comprehensive churn prediction system that identifies at-risk customers, enabling proactive retention strategies and maximizing customer lifetime value.

**Business Impact**:

- **85% Recall** - Identifies 85% of churning customers before they leave
- **$165K+ Annual Savings** - Projected revenue protection through targeted retention
- **1,900% ROI** - Return on investment for retention campaigns

---

## üéØ Key Results

| Metric        | Value | Impact                                   |
| ------------- | ----- | ---------------------------------------- |
| **Accuracy**  | 82%   | Overall prediction correctness           |
| **Precision** | 70%   | 70% of predicted churners actually churn |
| **Recall**    | 85%   | Catches 85% of all churning customers    |
| **F1-Score**  | 0.77  | Balanced performance metric              |
| **ROC-AUC**   | 0.87  | Strong discriminative ability            |

---

## üóÇÔ∏è Project Structure

```
customer-churn-analysis/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # Original dataset
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ telco_churn.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/                # Processed datasets
‚îÇ       ‚îú‚îÄ‚îÄ data_after_eda.csv
‚îÇ       ‚îî‚îÄ‚îÄ data_processed_final.csv
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                    # Jupyter notebooks (analysis workflow)
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb      # EDA & insights
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb   # Data preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ 03_modeling.ipynb              # Model training
‚îÇ   ‚îî‚îÄ‚îÄ 04_evaluation.ipynb            # Business impact analysis
‚îÇ
‚îú‚îÄ‚îÄ src/                          # Python source code (optional modules)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py           # Data loading utilities
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py         # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ model.py                 # Model training functions
‚îÇ   ‚îî‚îÄ‚îÄ evaluation.py            # Evaluation metrics
‚îÇ
‚îú‚îÄ‚îÄ models/                       # Trained models
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pkl          # Production model
‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl              # Feature scaler
‚îÇ   ‚îî‚îÄ‚îÄ model_comparison.csv    # Model performance comparison
‚îÇ
‚îú‚îÄ‚îÄ reports/                      # Generated reports
‚îÇ   ‚îú‚îÄ‚îÄ figures/                # Visualizations
‚îÇ   ‚îú‚îÄ‚îÄ customer_risk_segments.csv    # Risk scoring results
‚îÇ   ‚îî‚îÄ‚îÄ business_impact.csv     # ROI analysis
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ config.yaml                  # Configuration file
‚îú‚îÄ‚îÄ README.md                    # This file
‚îî‚îÄ‚îÄ LICENSE                      # MIT License
```

---

## üöÄ Getting Started

### Prerequisites

- Python 3.9 or higher
- pip package manager
- **Dataset**: Telco Customer Churn from Kaggle

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/customer-churn-analysis.git
cd customer-churn-analysis
```

2. **Create virtual environment** (recommended)

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Mac/Linux
source venv/bin/activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Download dataset**

- Download from [Kaggle - Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn?select=WA_Fn-UseC_-Telco-Customer-Churn.csv)
- Place `WA_Fn-UseC_-Telco-Customer-Churn.csv` in `data/raw/` folder
- Rename to `Telco-Customer-Churn.csv`

**Or if you already have the file:**

```bash
# Create data directories
mkdir -p data/raw data/processed

# Place your file in data/raw/
cp your-downloaded-file.csv data/raw/Telco-Customer-Churn.csv
```

---

## üìì Usage

### Running the Analysis

**Option 1: Jupyter Notebooks** (Recommended for exploration)

```bash
jupyter notebook
```

Then open notebooks in order:

1. `01_data_exploration.ipynb` - Understand the data
2. `02_feature_engineering.ipynb` - Prepare features
3. `03_modeling.ipynb` - Train models
4. `04_evaluation.ipynb` - Business impact

**Option 2: Python Scripts** (For production)

```python
# Load model and predict
import joblib
import pandas as pd

# Load trained model
model = joblib.load('models/best_model.pkl')
scaler = joblib.load('models/scaler.pkl')

# Prepare new customer data
new_customer = pd.DataFrame({
    # ... customer features
})

# Make prediction
churn_probability = model.predict_proba(new_customer)[:, 1]

# Assign risk segment
if churn_probability[0] >= 0.7:
    risk = 'High Risk - Immediate Intervention'
elif churn_probability[0] >= 0.4:
    risk = 'Medium Risk - Monitor Closely'
else:
    risk = 'Low Risk - Standard Engagement'

print(f"Churn Probability: {churn_probability[0]:.2%}")
print(f"Risk Segment: {risk}")
```

---

## üîç Analysis Workflow

### 1. Data Exploration (`01_data_exploration.ipynb`)

- **Dataset**: 7,043 customers with 21 features
- **Target**: Binary churn indicator (27% churn rate)
- **Key Findings**:
  - Month-to-month contracts show 3-4x higher churn
  - First 12 months are critical retention period
  - Churned customers pay 15-20% higher monthly charges

### 2. Feature Engineering (`02_feature_engineering.ipynb`)

- Created **16 engineered features**:

  - Tenure-based: `is_new_customer`, `is_long_term`, `tenure_bins`
  - Charge-based: `avg_monthly_spend`, `price_increase`, `high_monthly_charge`
  - Service-based: `total_services`, `has_internet`, `has_tech_support`
  - Contract-based: `is_month_to_month`, `has_auto_payment`
  - Demographic: `has_family`, `is_single_no_deps`

- Encoded categorical variables (one-hot + label encoding)
- Scaled numerical features (StandardScaler)
- Final dataset: **7,043 samples √ó 50+ features**

### 3. Model Development (`03_modeling.ipynb`)

- **Models Evaluated**:

  - Logistic Regression (baseline)
  - Decision Tree
  - Random Forest
  - Gradient Boosting

- **Hyperparameter Tuning**: GridSearchCV with 5-fold cross-validation
- **Best Model**: Random Forest (Tuned)
  - n_estimators=100, max_depth=15
  - F1-Score: 0.77
  - Achieved target 80%+ recall

### 4. Business Impact (`04_evaluation.ipynb`)

- **Risk Segmentation**:

  - High Risk (‚â•70% prob): Immediate intervention
  - Medium Risk (40-69% prob): Proactive monitoring
  - Low Risk (<40% prob): Standard engagement

- **Financial Analysis**:
  - Campaign Cost: $8,500
  - Revenue Saved: $170,000
  - Net Benefit: $161,500
  - ROI: 1,900%

---

## üí° Key Insights

### 1. Contract Type is Critical

- Month-to-month customers churn at **42%** vs 11% for two-year contracts
- **Recommendation**: Incentivize long-term contracts with discounts/perks

### 2. Early Tenure is High-Risk

- **35% of churn** occurs in first 3 months
- **Recommendation**: Enhanced onboarding program for new customers

### 3. Pricing Sensitivity

- Churned customers pay ~$15-20 more per month
- **Recommendation**: Review pricing strategy and value proposition

### 4. Predictive Power

- Model identifies **85% of churning customers**
- **70% precision** minimizes false alarms
- **Ready for production deployment**

---

## üéØ Business Recommendations

### Immediate Actions (Week 1-2)

- ‚úÖ Deploy model to production
- ‚úÖ Launch retention campaign for high-risk customers
- ‚úÖ A/B test contract incentives

### Short-Term (Month 1-3)

- üìã Implement enhanced onboarding
- üìã Create early warning dashboard
- üìã Review pricing for high-churn segments

### Long-Term (Quarter 1-2)

- üéØ Build real-time churn prediction API
- üéØ Integrate with CRM systems
- üéØ Expand to customer lifetime value prediction

---

## üìà Model Performance

### Confusion Matrix

|                      | Predicted: No Churn | Predicted: Churn |
| -------------------- | ------------------- | ---------------- |
| **Actual: No Churn** | 950 (TN)            | 80 (FP)          |
| **Actual: Churn**    | 45 (FN)             | 334 (TP)         |

- **True Negatives**: 950 correctly predicted retained customers
- **False Positives**: 80 false alarms (acceptable for retention campaigns)
- **False Negatives**: 45 missed churners (‚ö†Ô∏è minimize this!)
- **True Positives**: 334 correctly identified churners

---

## üõ†Ô∏è Technologies Used

- **Python 3.9+** - Core programming language
- **Pandas & NumPy** - Data manipulation
- **Scikit-learn** - Machine learning
- **Matplotlib & Seaborn** - Data visualization
- **Jupyter** - Interactive analysis
- **Git & GitHub** - Version control

---

## üìö Documentation

- [Data Dictionary](docs/data_dictionary.md) - Feature descriptions
- [Modeling Methodology](docs/methodology.md) - Technical approach
- [Business Case](docs/business_case.md) - ROI analysis
- [Deployment Guide](docs/deployment.md) - Production setup

---

## ü§ù Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

---

## üìù License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## üë§ Author

**Yunjae Jung**

- LinkedIn: [linkedin.com/in/yunjae-jung-99a13b221](https://www.linkedin.com/in/yunjae-jung-99a13b221/)
- GitHub: [@yoonjae0402](https://github.com/yoonjae0402)
- Email: yoonjae0402@gmail.com

---

## üôè Acknowledgments

- **Dataset**: Kaggle Telco Customer Churn dataset
- **Inspiration**: IBM Cognos Analytics sample datasets
- **Libraries**: scikit-learn, pandas, matplotlib communities
- **Resources**: Towards Data Science, Kaggle kernels

---

**Note**: This is a portfolio/educational project demonstrating end-to-end data science workflow. The model and insights should be validated with domain experts before production deployment.

---

_Last Updated: January 2026_
